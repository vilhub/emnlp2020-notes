---
id: 491a4381-329e-41e7-bb26-c777870a3041
title: Day2
desc: ''
updated: 1606001289977
created: 1605615533510
parent: b3810ead-5d53-4ecb-bd9c-a7e243e25ae3
children: []
fname: papers.mt.day2
hpath: papers.mt.day2
---
# Day2

## Losing Heads in the Lottery: Pruning Transformer Attention in Neural Machine Translation

Maximiliana Behnke, Kenneth Heafield 

<https://slideslive.com/38938739>
<https://www.aclweb.org/anthology/2020.emnlp-main.211>

[gswtranslation](6ea22ede-ae7b-4746-b548-2a60e608c4f7)

Pruning experiments
Prune heads early into the training

## Reusing a Pretrained Language Model on Languages with Limited Corpora for Unsupervised NMT

Alexandra Chronopoulou, Dario Stojanovski, Alexander Fraser 

<https://slideslive.com/38938785>
<https://www.aclweb.org/anthology/2020.emnlp-main.214>

UNMT for a high and a low resource language
Vocabulary extension method : union of vocabs
Use of adapters for efficient finetuning

