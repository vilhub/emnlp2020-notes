---
id: afc4c5c6-49d8-4563-857c-5aa0d0ff0e99
title: Keynotes
desc: ''
updated: 1606047673426
created: 1605537883680
parent: root
children: []
fname: keynotes
hpath: keynotes
---
# Keynotes

## Information Extraction Through the Years: How Did We Get Here?

Claire Cardie

- Information extraction : Extract and organize information from text
- 1991 : answer fixed questions : who what where how?
  Challenges : Noun-Phrase coreference resolution, event coref resolution
  Grammars constructed by hand mostly for syntactic POS parsers
  Top systems 60% precision, 50% recall
- 15 next years : Simplification by dividing the task : NER, sequence tagging, classification for relation extraction
- Now : E2E NN approaches
  SoTA :
  - NER : Contextualized character-level embeddings
  - Relation extraction (classification)
  - Entity + Relation : LSTM, ..

## Importance of intelligibility in ML

Keynote : Rich Caruana

<https://virtual.2020.emnlp.org/plenary_session_keynote_by_rich_caruana.html>
<https://github.com/interpretml/interpret>

![](/assets/images/2020-11-22-13-15-42.png)
[interesting](8c716ab6-e253-4b05-8167-ad399382adbb)

Explainable Boosting Machines

![](/assets/images/2020-11-18-00-06-36.png)

EBMs are really good for tabular data and perform as well as black box models but are interpretable

![](/assets/images/2020-11-18-00-09-58.png)

![](/assets/images/2020-11-18-00-13-12.png)

Model says asthma leads to lower pneumonia risk : because patients with asthma get to care quicker.

Can edit the model to get rid of these strange correlations

![](/assets/images/2020-11-18-00-19-52.png)

Can also be used with NLP using counts of n-grams

Best paper award ACL :
![](/assets/images/2020-11-18-00-36-48.png)
<https://github.com/marcotcr/checklist>

