---
id: 8129589b-ebd7-41fb-91e0-c7866143ea00
title: Day1
desc: ''
updated: 1606047673424
created: 1605544960870
parent: 621a796c-bed6-41bb-969f-9016a621e87d
children: []
fname: papers.applications.day1
hpath: papers.applications.day1
---
# Day1

## Data Weighted Training Strategies for Grammatical Error Correction

Jared Lichtarge, Chris Alberti, Shankar Kumar 

<https://slideslive.com/38939401>
<https://arxiv.org/abs/2008.02976>

- Grammatical error correction a "translation" task
- Problem : data contains a lot of low quality "grammatical error" corrections like in wiki revision history which could be complete fixes
- Delta-perplexity : Difference between perplexity given by pretrained model and finetuned model
  If perplexity of an example goes down after finetuning, data point must be similar to pretraining data, if it goes up, must be dissimilar
- Apply quality filtering during training by using these delta-perplexity quality scores :
  - Throw away bad data
  - Weigh by quality
  - Above + curriculum
    ![](emnlp2020-notes/assets/images/2020-11-22-13-15-42.png)
    [interesting](8c716ab6-e253-4b05-8167-ad399382adbb)

## FIND: Human-in-the-Loop Debugging Deep Text Classifiers

Piyawat Lertvittayakumjorn, Lucia Specia, Francesca Toni 

<https://slideslive.com/38939233>
<https://www.aclweb.org/anthology/2020.emnlp-main.24>

- Biases in the data might lead to bad predictions or not perform well with new data

- If we don't know problems in advance we can use post-hoc human in the loop approach

- Idea : propose post-hoc human in the loop approach to use feature debugging / disabling

1. Understand patterns that each learned feature detects
2. Disable irrelevant features
3. Fine-tune the model again

- CNNs : Show word cloud to the labeler to show which n-grams were chosen by max-pooling of CNN
  Human rates : is this feature useful for the classification task?

## Conversational Document Prediction to Assist Customer Care Agents

Jatin Ganhotra, Haggai Roitman, Doron Cohen, Nathaniel Mills, Chulaka Gunasekara, Yosi Mass, Sachindra Joshi, Luis Lastras, David Konopnicki 

<https://slideslive.com/38938896>
<https://www.aclweb.org/anthology/2020.emnlp-main.25>

- Idea : Suggest URLs to customers to solve their problems from chat conversations with agents

Methods :
Information retrieval : BM25
NNs : ESIM, BERT, SBERT

Hybrid approach : IR model for initial ranking, top 20 documents and then use ESIM model to speed up
Significant decrease in performance by using only BERT, better using IR + ESIM and faster
![](emnlp2020-notes/assets/images/2020-11-22-13-15-42.png)
[interesting](8c716ab6-e253-4b05-8167-ad399382adbb)

