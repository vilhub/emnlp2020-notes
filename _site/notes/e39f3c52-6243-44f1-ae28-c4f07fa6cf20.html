<!DOCTYPE html> <html lang="en-US"> <head> <meta charset="UTF-8"> <meta http-equiv="X-UA-Compatible" content="IE=Edge"> <title>High Performance NLP - Dendron</title> <link rel="shortcut icon" href="http://localhost:4000/favicon.ico" type="image/x-icon"> <link rel="stylesheet" href="http://localhost:4000/assets/css/just-the-docs-default.css"> <script type="text/javascript" src="http://localhost:4000/assets/js/vendor/lunr.min.js"></script> <script type="text/javascript" src="http://localhost:4000/assets/js/just-the-docs.js"></script> <meta name="viewport" content="width=device-width, initial-scale=1"> <!-- Begin Jekyll SEO tag v2.6.1 --> <title>High Performance NLP | Dendron</title> <meta name="generator" content="Jekyll v3.9.0" /> <meta property="og:title" content="High Performance NLP" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="Dendron is a local-first, markdown based, hierarchical note taking tool. It is meant to help you create, organize, and collaborate on knowledge bases of any size." /> <meta property="og:description" content="Dendron is a local-first, markdown based, hierarchical note taking tool. It is meant to help you create, organize, and collaborate on knowledge bases of any size." /> <link rel="canonical" href="http://localhost:4000/notes/e39f3c52-6243-44f1-ae28-c4f07fa6cf20.html" /> <meta property="og:url" content="http://localhost:4000/notes/e39f3c52-6243-44f1-ae28-c4f07fa6cf20.html" /> <meta property="og:site_name" content="Dendron" /> <meta property="og:image" content="http://localhost:4000/assets/images/logo.png" /> <meta name="twitter:card" content="summary" /> <meta property="twitter:image" content="http://localhost:4000/assets/images/logo.png" /> <meta property="twitter:title" content="High Performance NLP" /> <meta name="twitter:site" content="@dendronhq" /> <meta name="twitter:creator" content="@dendronhq" /> <script type="application/ld+json"> {"@type":"WebPage","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/assets/images/logo.png"}},"image":"http://localhost:4000/assets/images/logo.png","headline":"High Performance NLP","description":"Dendron is a local-first, markdown based, hierarchical note taking tool. It is meant to help you create, organize, and collaborate on knowledge bases of any size.","url":"http://localhost:4000/notes/e39f3c52-6243-44f1-ae28-c4f07fa6cf20.html","@context":"https://schema.org"}</script> <!-- End Jekyll SEO tag --> </head> <body> <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> <symbol id="svg-link" viewBox="0 0 24 24"> <title>Link</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"> <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"> <title>Search</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"> <title>Menu</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"> <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"> <title>Expand</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"> <polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"> <title>Document</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"> <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> </svg> <div class="side-bar"> <div class="site-header"> <a href="http://localhost:4000/" class="site-title lh-tight"> <div class="site-logo"></div> </a> <a href="#" id="menu-button" class="site-button"> <svg viewBox="0 0 24 24" class="icon"><use xlink:href="#svg-menu"></use></svg> </a> </div> <nav role="navigation" aria-label="Main" id="site-nav" class="site-nav"><ul class="nav-list"><li class="nav-list-item active"><a href="http://localhost:4000/" class="nav-list-link active">Emnlp 2020</a><ul class="nav-list"><li class="nav-list-item"><a href="http://localhost:4000/notes/8c716ab6-e253-4b05-8167-ad399382adbb.html" class="nav-list-link">Interesting</a></li><li class="nav-list-item"><a href="http://localhost:4000/notes/afc4c5c6-49d8-4563-857c-5aa0d0ff0e99.html" class="nav-list-link">Keynotes</a></li><li class="nav-list-item active"><a href="" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/notes/7070ae65-b6fc-4d6d-933f-e72b95614dc6.html" class="nav-list-link active">Papers</a><ul class="nav-list"><li class="nav-list-item"><a href="http://localhost:4000/notes/af4d40fb-5e41-460e-ae29-8a273b68c820.html" class="nav-list-link">Blackbox NLP Workshop</a></li><li class="nav-list-item"><a href="" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/notes/1977e2ad-5e1e-4f0e-94a1-b68059392e5e.html" class="nav-list-link">Classification</a><ul class="nav-list"><li class="nav-list-item"><a href="http://localhost:4000/notes/ef4348a5-1177-4d93-a8e7-018dea2dfa3d.html" class="nav-list-link">Day1</a></li><li class="nav-list-item"><a href="http://localhost:4000/notes/72bc9559-9ccf-41f9-952f-a031c81f2a20.html" class="nav-list-link">Day2</a></li><li class="nav-list-item"><a href="http://localhost:4000/notes/39c5c37c-995a-46c6-9623-2c3e4facc2df.html" class="nav-list-link">Day3</a></li></ul></li><li class="nav-list-item"><a href="" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/notes/40fbde60-26fc-4182-b55f-fae3e43b4074.html" class="nav-list-link">Dialogue</a><ul class="nav-list"><li class="nav-list-item"><a href="http://localhost:4000/notes/450266f8-502d-4d30-a104-0cde447ab1f8.html" class="nav-list-link">Day1</a></li><li class="nav-list-item"><a href="http://localhost:4000/notes/fcaac294-0f35-4af8-911a-269488faad77.html" class="nav-list-link">Day2</a></li><li class="nav-list-item"><a href="http://localhost:4000/notes/5bdfc9e6-b994-41fd-afad-9feb45f735f2.html" class="nav-list-link">Day3</a></li></ul></li><li class="nav-list-item"><a href="" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/notes/6571e39d-d925-403b-8f7a-cfa2749cb1a3.html" class="nav-list-link">Interpretability</a><ul class="nav-list"><li class="nav-list-item"><a href="http://localhost:4000/notes/c0486dab-c704-49a3-895c-dc14fb8b73a3.html" class="nav-list-link">Day2</a></li></ul></li><li class="nav-list-item"><a href="" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/notes/b87fe030-dae9-4a87-a76b-5f800841be77.html" class="nav-list-link">Language Generation</a><ul class="nav-list"><li class="nav-list-item"><a href="http://localhost:4000/notes/58571320-e5ea-4b81-8f63-4fa33cca7d15.html" class="nav-list-link">Day2</a></li></ul></li><li class="nav-list-item"><a href="" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/notes/b3810ead-5d53-4ecb-bd9c-a7e243e25ae3.html" class="nav-list-link">Machine Translation</a><ul class="nav-list"><li class="nav-list-item"><a href="http://localhost:4000/notes/2e97ac15-f73b-4e75-85f6-010d62ae98f4.html" class="nav-list-link">Day1</a></li><li class="nav-list-item"><a href="http://localhost:4000/notes/491a4381-329e-41e7-bb26-c777870a3041.html" class="nav-list-link">Day2</a></li></ul></li><li class="nav-list-item"><a href="" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/notes/621a796c-bed6-41bb-969f-9016a621e87d.html" class="nav-list-link">NLP Applications</a><ul class="nav-list"><li class="nav-list-item"><a href="http://localhost:4000/notes/8129589b-ebd7-41fb-91e0-c7866143ea00.html" class="nav-list-link">Day1</a></li></ul></li><li class="nav-list-item"><a href="http://localhost:4000/notes/4117ef1d-6d6d-4dbd-8eb5-df99cf907d46.html" class="nav-list-link">Negative results workshop</a></li><li class="nav-list-item"><a href="" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/notes/67da1849-168f-4915-996d-56a7effff761.html" class="nav-list-link">Other</a><ul class="nav-list"><li class="nav-list-item"><a href="http://localhost:4000/notes/357e62a6-2f5a-4fb9-b14f-dd71be43ce2c.html" class="nav-list-link">Day1</a></li><li class="nav-list-item"><a href="http://localhost:4000/notes/a3ae46a6-b224-4adf-a7aa-d6017e2206fc.html" class="nav-list-link">Day2</a></li><li class="nav-list-item"><a href="http://localhost:4000/notes/972ac840-7000-4a47-aa46-2773e8c3ef60.html" class="nav-list-link">Day3</a></li></ul></li><li class="nav-list-item"><a href="" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/notes/21d5cfbc-3752-4c20-b4f6-b13768bdbc0e.html" class="nav-list-link">Summarization</a><ul class="nav-list"><li class="nav-list-item"><a href="http://localhost:4000/notes/c4a11d84-5ea1-48d6-81be-e7439df2ef55.html" class="nav-list-link">Day1</a></li><li class="nav-list-item"><a href="http://localhost:4000/notes/1c302c5d-7da9-406e-8b5e-5b7777daeffc.html" class="nav-list-link">Day2</a></li></ul></li><li class="nav-list-item"><a href="" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/notes/11e3fe8a-98b7-4bb7-8fc9-fe1c29354461.html" class="nav-list-link">Transformers</a><ul class="nav-list"><li class="nav-list-item"><a href="http://localhost:4000/notes/948323c7-b75c-42e8-bb35-849463e56ea3.html" class="nav-list-link">Day1</a></li><li class="nav-list-item"><a href="http://localhost:4000/notes/3da29f21-7b4c-4d81-b230-b38455ccbc84.html" class="nav-list-link">Day2</a></li><li class="nav-list-item"><a href="http://localhost:4000/notes/71cc84f8-b271-498e-a001-c6e6d10b7c01.html" class="nav-list-link">Day3</a></li></ul></li><li class="nav-list-item active"><a href="" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/notes/27e6f1c1-1025-4574-b056-e9e00e4b6ce5.html" class="nav-list-link active">Tutorials</a><ul class="nav-list"><li class="nav-list-item active"><a href="http://localhost:4000/notes/e39f3c52-6243-44f1-ae28-c4f07fa6cf20.html" class="nav-list-link active">High Performance NLP</a></li><li class="nav-list-item"><a href="http://localhost:4000/notes/f3bc9db2-5cbb-4cdf-9845-af076d2f77f4.html" class="nav-list-link">Interpretability tutorial</a></li></ul></li><li class="nav-list-item"><a href="" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/notes/d3081c7a-2e55-4c60-8440-6d1f03e44481.html" class="nav-list-link">Workshop on Machine Translation</a><ul class="nav-list"><li class="nav-list-item"><a href="http://localhost:4000/notes/6a95a05d-8cc2-4f23-b59f-dc9c93cde9d2.html" class="nav-list-link">Low Resource Task</a></li></ul></li><li class="nav-list-item"><a href="http://localhost:4000/notes/8d1a05b3-9eea-41b3-97cf-00a5fa7a9d55.html" class="nav-list-link">Workshop on Noisy User-Generated Text</a></li></ul></li></ul></li></ul></nav> <footer class="site-footer"> üå± with üíï using <a href="https://www.dendron.so/"> Dendron üå≤ </a> </footer> </div> <div class="main" id="top"> <div id="main-header" class="main-header"> <div class="search"> <div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search Dendron" aria-label="Search Dendron" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label> </div> <div id="search-results" class="search-results"></div> </div> </div> <div id="main-content-wrap" class="main-content-wrap"> <nav aria-label="Breadcrumb" class="breadcrumb-nav"> <ol class="breadcrumb-nav-list"><li class="breadcrumb-nav-list-item"><a href="http://localhost:4000/">Emnlp 2020</a></li><li class="breadcrumb-nav-list-item"><a href="http://localhost:4000/notes/7070ae65-b6fc-4d6d-933f-e72b95614dc6.html">Papers</a></li><li class="breadcrumb-nav-list-item"><a href="http://localhost:4000/notes/27e6f1c1-1025-4574-b056-e9e00e4b6ce5.html">Tutorials</a></li><li class="breadcrumb-nav-list-item">High Performance NLP</li></ol> </nav> <div id="main-content" class="main-content" role="main"> <h1 id="high-performance-nlp-tutorial"> <a href="#high-performance-nlp-tutorial" aria-labelledby="high-performance-nlp-tutorial" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> High performance NLP tutorial </h1> <p><a href="https://slideslive.com/38940826">https://slideslive.com/38940826</a></p> <p><img src="/assets/images/2020-11-20-14-26-58.png" alt="" /></p> <p>Balance between theoretically promising and practically achievable models</p> <ol> <li>Techniques : <ul> <li>Distillation</li> <li>Quantization</li> <li>Pruning</li> </ul> </li> <li>Efficient attention <ul> <li>Data independent patterns</li> <li>Data dependent patterns</li> <li>Alternative attention mechanisms</li> <li>Recurrence</li> </ul> </li> <li>Case studies</li> <li>Scaling in practice <ul> <li>Scaling laws of LMs</li> <li>Parallelism techniques</li> <li>Methods to reduce memory footprint</li> <li>Mixture of experts</li> </ul> </li> </ol> <h2 id="fundamentals"> <a href="#fundamentals" aria-labelledby="fundamentals" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Fundamentals </h2> <p><img src="/assets/images/2020-11-20-14-38-33.png" alt="" /> <img src="/assets/images/2020-11-20-14-40-06.png" alt="" /></p> <p><img src="/assets/images/2020-11-20-14-41-24.png" alt="" /> <img src="/assets/images/2020-11-20-14-42-30.png" alt="" /></p> <p><img src="/assets/images/2020-11-20-14-44-32.png" alt="" /> <img src="/assets/images/2020-11-20-14-44-49.png" alt="" /></p> <h2 id="core-techniques"> <a href="#core-techniques" aria-labelledby="core-techniques" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Core techniques </h2> <h3 id="distillation"> <a href="#distillation" aria-labelledby="distillation" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Distillation </h3> <p>Use soft labels to convey uncertainty / nuances to student model</p> <p>When should distillation happen? Pretraining, finetuning, both?</p> <h4 id="pretraining"> <a href="#pretraining" aria-labelledby="pretraining" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Pretraining </h4> <p>DistilBERT, distillation at pretraining. Less layers</p> <ol> <li>Take pretrained BERT base as teacher</li> <li>Keep its bottom 6 layers only, shallow student</li> <li>Continue training the 6 layer via knowledge distillation : use teacher probabilities as guide</li> </ol> <p>MobileBERT, also distil at pretraining. Same number of layers as teacher but smaller embedding size. Encourage at each layer alignment of :</p> <ul> <li>Feature maps (challenge : different dims), up and down projections to 512 in between dims</li> <li>Attention maps : want the student to know where to focus attention, minimize KL divergence between attention distributions <img src="/assets/images/2020-11-20-14-57-08.png" alt="" /></li> </ul> <p>Comparable accuracy on GLUE, 4x smaller, 6x faster than BERT Base</p> <h4 id="fine-tuning"> <a href="#fine-tuning" aria-labelledby="fine-tuning" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Fine-tuning </h4> <p><img src="/assets/images/2020-11-20-14-59-17.png" alt="" /></p> <p>Useful when we have large amounts of in-domain task data without gold labels, can use teacher labels</p> <h4 id="both"> <a href="#both" aria-labelledby="both" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Both </h4> <p>TinyBERT <img src="/assets/images/2020-11-20-15-00-20.png" alt="" /></p> <h3 id="quantization"> <a href="#quantization" aria-labelledby="quantization" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Quantization </h3> <p><img src="/assets/images/2020-11-20-15-41-40.png" alt="" /></p> <p>When to quantize?</p> <ul> <li>Most convenient : post-training, often drop in accuracy</li> <li>Even if using fine-tuning step after, can be unsatisfactory</li> </ul> <p>Solution : Quantization-aware training or Simulated quantization</p> <ul> <li>Forward pass : As if quantized</li> <li>Backward pass : Normal</li> </ul> <p>Models that quantize weights and also activations : <img src="/assets/images/2020-11-20-15-46-40.png" alt="" /></p> <ul> <li>Q8BERT : same forward / backward strategy as above</li> <li>Q-BERT : Each layer has own quantization, group precision to save on memory</li> <li>TernaryBERT : <a href="948323c7-b75c-42e8-bb35-849463e56ea3">papers.transformers.day1</a> -1, 0 or 1. Distillation + quantization 15x decrease in size 2 bits per parameter, 2 students <img src="/assets/images/2020-11-20-15-53-45.png" alt="" /></li> </ul> <p>Loss :</p> <ul> <li>Student full precision diff with quantized student</li> <li>Distillation loss, cross-entropy studen teacher</li> <li>MSE distance between hidden layers and attention scores</li> </ul> <h3 id="pruning"> <a href="#pruning" aria-labelledby="pruning" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Pruning </h3> <p>Not only more efficient, can be seen as tech to improve generalization</p> <p><img src="/assets/images/2020-11-20-17-30-23.png" alt="" /></p> <p>Early ideas : prune based on second order derivatives</p> <p>Why do we need to start with large network and downsize instead of training the small one?</p> <h4 id="lottery-ticket-hypothesis"> <a href="#lottery-ticket-hypothesis" aria-labelledby="lottery-ticket-hypothesis" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Lottery ticket hypothesis </h4> <p>The larger the network, the more lottery tickets (possible subnetworks) and therefore the larger the chances of finding one that performs well.</p> <p>The smaller model can be trained in isolation.</p> <p><img src="/assets/images/2020-11-20-17-35-55.png" alt="" /></p> <p>Iterative pruning is efficient, iterate pruning + fine-tuning</p> <p>In practice : fails on very deep networks where it cannot find a winning ticket</p> <p>Revisited more stable network : <img src="/assets/images/2020-11-20-17-38-40.png" alt="" /></p> <p>NMT : <img src="/assets/images/2020-11-20-17-40-17.png" alt="" /></p> <h4 id="movement-pruning"> <a href="#movement-pruning" aria-labelledby="movement-pruning" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Movement pruning </h4> <p>Apply pruning during fine-tuning to reuse pretrained models</p> <p>Magnitude pruning doesn‚Äôt perform well in transfer learning =&gt; movement pruning</p> <p>Every parameter is associated with a learned importance score</p> <p><img src="/assets/images/2020-11-20-17-45-35.png" alt="" /></p> <p>95% accuracy of BERT base while keeping 15% of its parameters</p> <p>Previous methods : unstructured pruning, mostly memory saving since sparse compute poorly supported</p> <p>Hardware lottery : the methods that are most adapted to current hardware become the popular ones <img src="/assets/images/2020-11-20-17-46-43.png" alt="" /></p> <h2 id="efficient-attention"> <a href="#efficient-attention" aria-labelledby="efficient-attention" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Efficient attention </h2> <p>Quadratic bottleneck in length, problem for :</p> <ul> <li>Long-range dependencies</li> <li>Character level models</li> <li>Speech processing</li> <li>High resolution image processing</li> </ul> <p><img src="/assets/images/2020-11-20-17-50-28.png" alt="" /></p> <h3 id="data-independent-patterns"> <a href="#data-independent-patterns" aria-labelledby="data-independent-patterns" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Data independent patterns </h3> <p><img src="/assets/images/2020-11-20-18-00-23.png" alt="" /></p> <p>Fixed patterns on attention matrix and sparsify</p> <ul> <li>Blockwise patterns : reduction to being quadratic in block length <img src="/assets/images/2020-11-20-18-03-55.png" alt="" /></li> <li>Strided patterns : reduction by constant factor <img src="/assets/images/2020-11-20-18-04-31.png" alt="" /></li> <li>Diagonal patterns : <img src="/assets/images/2020-11-20-18-05-12.png" alt="" /></li> <li>Random patterns : <img src="/assets/images/2020-11-20-18-05-39.png" alt="" /></li> <li>Global attention : <img src="/assets/images/2020-11-20-18-05-58.png" alt="" /></li> <li>Combination of patterns <img src="/assets/images/2020-11-20-18-06-20.png" alt="" /></li> </ul> <h3 id="data-dependent-patterns"> <a href="#data-dependent-patterns" aria-labelledby="data-dependent-patterns" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Data dependent patterns </h3> <p><img src="/assets/images/2020-11-20-18-01-39.png" alt="" /></p> <ul> <li>Buckets <img src="/assets/images/2020-11-20-18-07-14.png" alt="" /> Reformer : use LSH and look at only items in same bucket during attention <img src="/assets/images/2020-11-20-18-08-26.png" alt="" /> Clustering over activation : Routing transformer, clustered attention</li> <li>Sorting and blocking : Sort and restrict attention to only current block or neighbours : Sinkhorn Transformer</li> <li>Compression : Attention matrix has been empirically demonstrated to be approximately low rank <img src="/assets/images/2020-11-20-18-11-21.png" alt="" /></li> </ul> <h3 id="kernels-and-alternative-attention-mechanisms"> <a href="#kernels-and-alternative-attention-mechanisms" aria-labelledby="kernels-and-alternative-attention-mechanisms" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Kernels and alternative attention mechanisms </h3> <p><img src="/assets/images/2020-11-20-18-02-24.png" alt="" /></p> <ul> <li>Kernels : Simplify attention $\phi(Q, K) =exp(\frac{Q^T K}{\sqrt{d}})$ into decomposable kernel $\phi(Q)^T \phi(K)$ <img src="/assets/images/2020-11-20-18-14-05.png" alt="" /> If we can do this, no need to pay quadratic price =&gt; linear <img src="/assets/images/2020-11-20-18-16-59.png" alt="" /></li> </ul> <p>Proposed kernels : <img src="/assets/images/2020-11-20-18-18-17.png" alt="" /> Random features</p> <ul> <li> <p>Performer <img src="/assets/images/2020-11-20-18-19-09.png" alt="" /></p> </li> <li> <p>Synthesizers <img src="/assets/images/2020-11-20-18-20-56.png" alt="" /></p> </li> </ul> <h3 id="recurrence"> <a href="#recurrence" aria-labelledby="recurrence" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Recurrence </h3> <p><img src="/assets/images/2020-11-20-18-02-41.png" alt="" /></p> <ul> <li> <p>Transformer-XL : split sequences to different chunks, process them independently. Segment-level recurrence mechanism : no need to backprop through previous segment <img src="/assets/images/2020-11-20-18-22-35.png" alt="" /></p> </li> <li> <p>Compressive transformers : <img src="/assets/images/2020-11-20-18-23-57.png" alt="" /></p> </li> </ul> <h3 id="how-do-they-compare"> <a href="#how-do-they-compare" aria-labelledby="how-do-they-compare" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> How do they compare? </h3> <ul> <li>Benchmark : long range arena <img src="/assets/images/2020-11-20-18-24-47.png" alt="" /></li> </ul> <p><img src="/assets/images/2020-11-20-18-25-37.png" alt="" /></p> <ul> <li> <p>Time performance per step <img src="/assets/images/2020-11-20-18-26-23.png" alt="" /></p> </li> <li> <p>Memory performance <img src="/assets/images/2020-11-20-18-26-50.png" alt="" /></p> </li> <li> <p>Summary <img src="/assets/images/2020-11-20-18-27-10.png" alt="" /></p> </li> </ul> <h2 id="use-cases"> <a href="#use-cases" aria-labelledby="use-cases" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Use cases </h2> <h3 id="language-models"> <a href="#language-models" aria-labelledby="language-models" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Language models </h3> <ul> <li>Evolved transformer : Uses neural architecture search to improve structure, same performance, 38% smaller</li> <li>PRADO : <img src="/assets/images/2020-11-20-18-35-44.png" alt="" /></li> <li>Lite Transformer Long-Short range attention : long distance by attention, local context by convolution 2.5x reduced computation, 18x smaller, no need for 250 GPU year NAS cost</li> <li>.. A bunch of others</li> </ul> <h3 id="retrieval"> <a href="#retrieval" aria-labelledby="retrieval" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Retrieval </h3> <p>Data as integral parts of models, ability to retrieve it during inference</p> <ul> <li>Sentence-BERT : siamese networks with BERT for better retrieval <img src="/assets/images/2020-11-20-18-42-31.png" alt="" /> With classic sentence A [ SEP ] sentence B, would need to reencode the whole dataset at inference -&gt; separate encoders and cosine distance <img src="/assets/images/2020-11-20-18-44-36.png" alt="" /></li> </ul> <p>Most similar datapoints can be found in sublinear time using Maximum inner product search tools <img src="/assets/images/2020-11-20-18-46-06.png" alt="" /></p> <ul> <li> <p>Generalization through Memorization : NN LMs Interpolate BERT with k-NN <img src="/assets/images/2020-11-20-18-48-15.png" alt="" /> <img src="/assets/images/2020-11-20-18-49-05.png" alt="" /></p> </li> <li> <p>REALM : Retrieval-Augmented LM Pretraining Can store knowledge by storing it in network but limited by network size Use dual encoder from above to retrieve data <img src="/assets/images/2020-11-20-18-51-13.png" alt="" /></p> </li> </ul> <p>Inference <img src="/assets/images/2020-11-20-18-51-57.png" alt="" /> SoTA on Open-QA</p> <p>Can be better and more performant with retrieval <img src="/assets/images/2020-11-20-18-53-41.png" alt="" /></p> <h2 id="scaling-in-practice"> <a href="#scaling-in-practice" aria-labelledby="scaling-in-practice" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Scaling in practice </h2> <h3 id="hardware"> <a href="#hardware" aria-labelledby="hardware" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Hardware </h3> <p>Scale more important than architecture but attention is better <img src="/assets/images/2020-11-20-18-55-22.png" alt="" /></p> <p>(Attention size saturation might be due to internet data WebCrawl which has a relatively small attention span) <img src="/assets/images/2020-11-20-18-57-13.png" alt="" /></p> <p>Fully connected layers consume most of the compute <img src="/assets/images/2020-11-20-18-59-09.png" alt="" /></p> <p>Theoretical vs experimental perspective : <img src="/assets/images/2020-11-20-19-04-39.png" alt="" /></p> <p>Argues for not using FLOPS but wall time</p> <p>Theory vs practice, consider hardware you run on : <img src="/assets/images/2020-11-20-19-05-49.png" alt="" /></p> <p>Other example : EfficientNet is more efficient in FLOPS but runs slower than other image algorithms</p> <p>For Tensor cores on GPU : mat mul low utilization of FLOPs <img src="/assets/images/2020-11-21-17-43-46.png" alt="" /></p> <p>Sparsity might be needing 10x less FLOPs but 5x slower than dense so only 2x speedup <img src="/assets/images/2020-11-21-17-44-53.png" alt="" /></p> <p>Trade-off but no perf gains <img src="/assets/images/2020-11-21-17-45-47.png" alt="" /></p> <p>BERT base is too small to utilize full GPU <img src="/assets/images/2020-11-21-17-46-20.png" alt="" /></p> <p>Mat mul can be more efficient if we use less of the GPU : can increase resources per subcore within SM to speedup <img src="/assets/images/2020-11-21-17-48-01.png" alt="" /></p> <p>Conclusion <img src="/assets/images/2020-11-21-17-48-33.png" alt="" /></p> <h3 id="memory-optimization"> <a href="#memory-optimization" aria-labelledby="memory-optimization" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Memory optimization </h3> <p>How to fit models into memory? <img src="/assets/images/2020-11-21-17-50-02.png" alt="" /></p> <ul> <li>CPU / GPU memory swapping e.g. only have one hot layer, swap to CPU what is not needed <img src="/assets/images/2020-11-21-17-51-18.png" alt="" /></li> </ul> <p>Benefits for large batch sizes <img src="/assets/images/2020-11-21-17-51-48.png" alt="" /></p> <ul> <li> <p>Mixed precision training : Multiply output loss by scale to avoid over/underflow <img src="/assets/images/2020-11-21-17-53-05.png" alt="" /> BF16 on newer GPUs : no need for loss scaling</p> </li> <li> <p>Gradient checkpointing : <img src="/assets/images/2020-11-21-17-56-52.png" alt="" /></p> </li> </ul> <p>Trade memory for computations : <img src="/assets/images/2020-11-21-17-57-29.png" alt="" /></p> <p>pytorch easy to use : torch.utils.checkpoint</p> <ul> <li> <p>Reversible residual connections Usually, prefer gradient checkpointing <img src="/assets/images/2020-11-21-17-59-05.png" alt="" /></p> </li> <li> <p>Gradient accumulation Simulate training of larger batch sizes using small batch sizes <img src="/assets/images/2020-11-21-18-00-05.png" alt="" /></p> </li> </ul> <h3 id="parallelism"> <a href="#parallelism" aria-labelledby="parallelism" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Parallelism </h3> <ul> <li> <p>Data parallelism Distribute gradient computations, gather them on all devices and do the update <img src="/assets/images/2020-11-21-18-02-32.png" alt="" /></p> </li> <li> <p>Model parallelism Aplit layers across devices Efficient if output of model is small but layers have lots of weights : good for feedforward, bad for attention <img src="/assets/images/2020-11-21-18-03-23.png" alt="" /></p> </li> <li> <p>Pipeline parallelism Model as pipeline and pass data to next device when done <img src="/assets/images/2020-11-21-18-05-07.png" alt="" /></p> </li> <li> <p>ZeRO parallelism opt <img src="/assets/images/2020-11-21-18-07-01.png" alt="" /></p> </li> <li> <p>3D parallelism All parallelisms combined, can train 1 trillion parameter models with relatively few devices <img src="/assets/images/2020-11-21-18-08-47.png" alt="" /></p> </li> </ul> <h3 id="efficiency-optimizations"> <a href="#efficiency-optimizations" aria-labelledby="efficiency-optimizations" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Efficiency optimizations </h3> <ul> <li> <p>Larger batch sizes Enables larger learning rates, speeds up training <img src="/assets/images/2020-11-21-18-10-23.png" alt="" /></p> </li> <li> <p>Fused kernels e.g. during Adam : lots of load / store operations =&gt; load all things we need and then compute <img src="/assets/images/2020-11-21-18-11-36.png" alt="" /></p> </li> </ul> <h3 id="mixture-of-experts"> <a href="#mixture-of-experts" aria-labelledby="mixture-of-experts" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Mixture of Experts </h3> <p>Very large models that can be scaled efficiently Can be 1000x more efficient than Transformers</p> <p>MoE layer: Split feedfoward layer into ‚Äúexperts‚Äù and select a few, only a few are active. Use gating mechanism to choose the experts. KeepTopK + Softmax, only push through selected experts and add them up <img src="/assets/images/2020-11-21-18-13-54.png" alt="" /></p> <p>MoE scales very well, 600B parameters (1024 experts), 1000x more efficient than GPT3 <img src="/assets/images/2020-11-21-18-15-36.png" alt="" /></p> <p>Problem : balancing experts, poor utilization</p> <p>Over time noise decreases and converges to few experts, needs counterbalancing over time, use weight to capture variation over time : <img src="/assets/images/2020-11-21-18-17-21.png" alt="" /></p> <p>Simpler version : Scale loss of gate probabilities proportional to how often an expert is picked to rebalance <img src="/assets/images/2020-11-21-18-23-20.png" alt="" /> <img src="/assets/images/2020-11-22-00-15-48.png" alt="" /></p> <p>MoE is difficult : <img src="/assets/images/2020-11-22-00-17-11.png" alt="" /></p> <p>MoE can be very efficient but can be difficult to get right <img src="/assets/images/2020-11-22-00-20-29.png" alt="" /></p> <hr> <footer> <p class="text-small text-grey-dk-000 mb-0"></p> </footer> </div> </div> <div class="search-overlay"></div> </div> </body> </html>
