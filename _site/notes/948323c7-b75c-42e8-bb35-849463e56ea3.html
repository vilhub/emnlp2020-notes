<!DOCTYPE html> <html lang="en-US"> <head> <meta charset="UTF-8"> <meta http-equiv="X-UA-Compatible" content="IE=Edge"> <title>Day1 - Dendron</title> <link rel="shortcut icon" href="http://localhost:4000/favicon.ico" type="image/x-icon"> <link rel="stylesheet" href="http://localhost:4000/assets/css/just-the-docs-default.css"> <script type="text/javascript" src="http://localhost:4000/assets/js/vendor/lunr.min.js"></script> <script type="text/javascript" src="http://localhost:4000/assets/js/just-the-docs.js"></script> <meta name="viewport" content="width=device-width, initial-scale=1"> <!-- Begin Jekyll SEO tag v2.6.1 --> <title>Day1 | Dendron</title> <meta name="generator" content="Jekyll v3.9.0" /> <meta property="og:title" content="Day1" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="Dendron is a local-first, markdown based, hierarchical note taking tool. It is meant to help you create, organize, and collaborate on knowledge bases of any size." /> <meta property="og:description" content="Dendron is a local-first, markdown based, hierarchical note taking tool. It is meant to help you create, organize, and collaborate on knowledge bases of any size." /> <link rel="canonical" href="http://localhost:4000/notes/948323c7-b75c-42e8-bb35-849463e56ea3.html" /> <meta property="og:url" content="http://localhost:4000/notes/948323c7-b75c-42e8-bb35-849463e56ea3.html" /> <meta property="og:site_name" content="Dendron" /> <meta property="og:image" content="http://localhost:4000/assets/images/logo.png" /> <meta name="twitter:card" content="summary" /> <meta property="twitter:image" content="http://localhost:4000/assets/images/logo.png" /> <meta property="twitter:title" content="Day1" /> <meta name="twitter:site" content="@dendronhq" /> <meta name="twitter:creator" content="@dendronhq" /> <script type="application/ld+json"> {"@type":"WebPage","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/assets/images/logo.png"}},"image":"http://localhost:4000/assets/images/logo.png","headline":"Day1","description":"Dendron is a local-first, markdown based, hierarchical note taking tool. It is meant to help you create, organize, and collaborate on knowledge bases of any size.","url":"http://localhost:4000/notes/948323c7-b75c-42e8-bb35-849463e56ea3.html","@context":"https://schema.org"}</script> <!-- End Jekyll SEO tag --> </head> <body> <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> <symbol id="svg-link" viewBox="0 0 24 24"> <title>Link</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"> <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"> <title>Search</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"> <title>Menu</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"> <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"> <title>Expand</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"> <polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"> <title>Document</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"> <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> </svg> <div class="side-bar"> <div class="site-header"> <a href="http://localhost:4000/" class="site-title lh-tight"> <div class="site-logo"></div> </a> <a href="#" id="menu-button" class="site-button"> <svg viewBox="0 0 24 24" class="icon"><use xlink:href="#svg-menu"></use></svg> </a> </div> <nav role="navigation" aria-label="Main" id="site-nav" class="site-nav"><ul class="nav-list"><li class="nav-list-item active"><a href="http://localhost:4000/" class="nav-list-link active">Emnlp 2020</a><ul class="nav-list"><li class="nav-list-item"><a href="http://localhost:4000/notes/8c716ab6-e253-4b05-8167-ad399382adbb.html" class="nav-list-link">Interesting</a></li><li class="nav-list-item"><a href="http://localhost:4000/notes/afc4c5c6-49d8-4563-857c-5aa0d0ff0e99.html" class="nav-list-link">Keynotes</a></li><li class="nav-list-item active"><a href="" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/notes/7070ae65-b6fc-4d6d-933f-e72b95614dc6.html" class="nav-list-link active">Papers</a><ul class="nav-list"><li class="nav-list-item"><a href="http://localhost:4000/notes/af4d40fb-5e41-460e-ae29-8a273b68c820.html" class="nav-list-link">Blackbox NLP Workshop</a></li><li class="nav-list-item"><a href="" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/notes/1977e2ad-5e1e-4f0e-94a1-b68059392e5e.html" class="nav-list-link">Classification</a><ul class="nav-list"><li class="nav-list-item"><a href="http://localhost:4000/notes/ef4348a5-1177-4d93-a8e7-018dea2dfa3d.html" class="nav-list-link">Day1</a></li><li class="nav-list-item"><a href="http://localhost:4000/notes/72bc9559-9ccf-41f9-952f-a031c81f2a20.html" class="nav-list-link">Day2</a></li><li class="nav-list-item"><a href="http://localhost:4000/notes/39c5c37c-995a-46c6-9623-2c3e4facc2df.html" class="nav-list-link">Day3</a></li></ul></li><li class="nav-list-item"><a href="" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/notes/40fbde60-26fc-4182-b55f-fae3e43b4074.html" class="nav-list-link">Dialogue</a><ul class="nav-list"><li class="nav-list-item"><a href="http://localhost:4000/notes/450266f8-502d-4d30-a104-0cde447ab1f8.html" class="nav-list-link">Day1</a></li><li class="nav-list-item"><a href="http://localhost:4000/notes/fcaac294-0f35-4af8-911a-269488faad77.html" class="nav-list-link">Day2</a></li><li class="nav-list-item"><a href="http://localhost:4000/notes/5bdfc9e6-b994-41fd-afad-9feb45f735f2.html" class="nav-list-link">Day3</a></li></ul></li><li class="nav-list-item"><a href="" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/notes/6571e39d-d925-403b-8f7a-cfa2749cb1a3.html" class="nav-list-link">Interpretability</a><ul class="nav-list"><li class="nav-list-item"><a href="http://localhost:4000/notes/c0486dab-c704-49a3-895c-dc14fb8b73a3.html" class="nav-list-link">Day2</a></li></ul></li><li class="nav-list-item"><a href="" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/notes/b87fe030-dae9-4a87-a76b-5f800841be77.html" class="nav-list-link">Language Generation</a><ul class="nav-list"><li class="nav-list-item"><a href="http://localhost:4000/notes/58571320-e5ea-4b81-8f63-4fa33cca7d15.html" class="nav-list-link">Day2</a></li></ul></li><li class="nav-list-item"><a href="" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/notes/b3810ead-5d53-4ecb-bd9c-a7e243e25ae3.html" class="nav-list-link">Machine Translation</a><ul class="nav-list"><li class="nav-list-item"><a href="http://localhost:4000/notes/2e97ac15-f73b-4e75-85f6-010d62ae98f4.html" class="nav-list-link">Day1</a></li><li class="nav-list-item"><a href="http://localhost:4000/notes/491a4381-329e-41e7-bb26-c777870a3041.html" class="nav-list-link">Day2</a></li></ul></li><li class="nav-list-item"><a href="" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/notes/621a796c-bed6-41bb-969f-9016a621e87d.html" class="nav-list-link">NLP Applications</a><ul class="nav-list"><li class="nav-list-item"><a href="http://localhost:4000/notes/8129589b-ebd7-41fb-91e0-c7866143ea00.html" class="nav-list-link">Day1</a></li></ul></li><li class="nav-list-item"><a href="http://localhost:4000/notes/4117ef1d-6d6d-4dbd-8eb5-df99cf907d46.html" class="nav-list-link">Negative results workshop</a></li><li class="nav-list-item"><a href="" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/notes/67da1849-168f-4915-996d-56a7effff761.html" class="nav-list-link">Other</a><ul class="nav-list"><li class="nav-list-item"><a href="http://localhost:4000/notes/357e62a6-2f5a-4fb9-b14f-dd71be43ce2c.html" class="nav-list-link">Day1</a></li><li class="nav-list-item"><a href="http://localhost:4000/notes/a3ae46a6-b224-4adf-a7aa-d6017e2206fc.html" class="nav-list-link">Day2</a></li><li class="nav-list-item"><a href="http://localhost:4000/notes/972ac840-7000-4a47-aa46-2773e8c3ef60.html" class="nav-list-link">Day3</a></li></ul></li><li class="nav-list-item"><a href="" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/notes/21d5cfbc-3752-4c20-b4f6-b13768bdbc0e.html" class="nav-list-link">Summarization</a><ul class="nav-list"><li class="nav-list-item"><a href="http://localhost:4000/notes/c4a11d84-5ea1-48d6-81be-e7439df2ef55.html" class="nav-list-link">Day1</a></li><li class="nav-list-item"><a href="http://localhost:4000/notes/1c302c5d-7da9-406e-8b5e-5b7777daeffc.html" class="nav-list-link">Day2</a></li></ul></li><li class="nav-list-item active"><a href="" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/notes/11e3fe8a-98b7-4bb7-8fc9-fe1c29354461.html" class="nav-list-link active">Transformers</a><ul class="nav-list"><li class="nav-list-item active"><a href="http://localhost:4000/notes/948323c7-b75c-42e8-bb35-849463e56ea3.html" class="nav-list-link active">Day1</a></li><li class="nav-list-item"><a href="http://localhost:4000/notes/3da29f21-7b4c-4d81-b230-b38455ccbc84.html" class="nav-list-link">Day2</a></li><li class="nav-list-item"><a href="http://localhost:4000/notes/71cc84f8-b271-498e-a001-c6e6d10b7c01.html" class="nav-list-link">Day3</a></li></ul></li><li class="nav-list-item"><a href="" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/notes/27e6f1c1-1025-4574-b056-e9e00e4b6ce5.html" class="nav-list-link">Tutorials</a><ul class="nav-list"><li class="nav-list-item"><a href="http://localhost:4000/notes/e39f3c52-6243-44f1-ae28-c4f07fa6cf20.html" class="nav-list-link">High Performance NLP</a></li><li class="nav-list-item"><a href="http://localhost:4000/notes/f3bc9db2-5cbb-4cdf-9845-af076d2f77f4.html" class="nav-list-link">Interpretability tutorial</a></li></ul></li><li class="nav-list-item"><a href="" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/notes/d3081c7a-2e55-4c60-8440-6d1f03e44481.html" class="nav-list-link">Workshop on Machine Translation</a><ul class="nav-list"><li class="nav-list-item"><a href="http://localhost:4000/notes/6a95a05d-8cc2-4f23-b59f-dc9c93cde9d2.html" class="nav-list-link">Low Resource Task</a></li></ul></li><li class="nav-list-item"><a href="http://localhost:4000/notes/8d1a05b3-9eea-41b3-97cf-00a5fa7a9d55.html" class="nav-list-link">Workshop on Noisy User-Generated Text</a></li></ul></li></ul></li></ul></nav> <footer class="site-footer"> üå± with üíï using <a href="https://www.dendron.so/"> Dendron üå≤ </a> </footer> </div> <div class="main" id="top"> <div id="main-header" class="main-header"> <div class="search"> <div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search Dendron" aria-label="Search Dendron" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label> </div> <div id="search-results" class="search-results"></div> </div> </div> <div id="main-content-wrap" class="main-content-wrap"> <nav aria-label="Breadcrumb" class="breadcrumb-nav"> <ol class="breadcrumb-nav-list"><li class="breadcrumb-nav-list-item"><a href="http://localhost:4000/">Emnlp 2020</a></li><li class="breadcrumb-nav-list-item"><a href="http://localhost:4000/notes/7070ae65-b6fc-4d6d-933f-e72b95614dc6.html">Papers</a></li><li class="breadcrumb-nav-list-item"><a href="http://localhost:4000/notes/11e3fe8a-98b7-4bb7-8fc9-fe1c29354461.html">Transformers</a></li><li class="breadcrumb-nav-list-item">Day1</li></ol> </nav> <div id="main-content" class="main-content" role="main"> <h1 id="day1"> <a href="#day1" aria-labelledby="day1" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Day1 </h1> <h2 id="pre-training-transformers-as-energy-based-cloze-models"> <a href="#pre-training-transformers-as-energy-based-cloze-models" aria-labelledby="pre-training-transformers-as-energy-based-cloze-models" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Pre-Training Transformers as Energy-Based Cloze Models </h2> <p>Kevin Clark, Minh-Thang Luong, Quoc Le, Christopher D. Manning</p> <p><a href="https://slideslive.com/38939095">https://slideslive.com/38939095</a> <a href="https://www.aclweb.org/anthology/2020.emnlp-main.20">https://www.aclweb.org/anthology/2020.emnlp-main.20</a></p> <ul> <li> <div class="table-wrapper"><table> <tbody> <tr> <td>Autoregressive LMs good for scoring sentences : P(a) _ P(b</td> <td>a) _ ‚Ä¶ but no easy way to do this with BERT due to masking task</td> </tr> </tbody> </table></div> </li> <li> <p>Idea : Electric model : predict all words simultaneously without masking</p> </li> <li> <p>Energy-based model, assigns a scalar score to each word. Does not use softmax but outputs unnormalized scores which avoids expensive renormalization</p> </li> <li> <p>Use noise contrastive estimation : turn generation task into binary classification task, model has to distinguish between in-distribution tokens / fake tokens</p> </li> <li> <p>Better than Electra, replace generator by noise distribution and discriminator by binary classifier</p> </li> <li> <p>ELECTRA is ‚Äúnegative sampling‚Äù version of BERT</p> </li> <li>Requires O(1) transformer passes to do scoring / reranking <img src="/assets/images/2020-11-22-13-15-42.png" alt="" /> <a href="8c716ab6-e253-4b05-8167-ad399382adbb">interesting</a></li> </ul> <h2 id="calibration-of-pre-trained-transformers"> <a href="#calibration-of-pre-trained-transformers" aria-labelledby="calibration-of-pre-trained-transformers" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Calibration of Pre-trained Transformers </h2> <p>Shrey Desai, Greg Durrett</p> <p><a href="https://slideslive.com/38939157">https://slideslive.com/38939157</a> <a href="https://www.aclweb.org/anthology/2020.emnlp-main.21">https://www.aclweb.org/anthology/2020.emnlp-main.21</a></p> <ul> <li> <p>BERT models can make mistakes with output probabilities =&gt; Need for posterior calibration</p> </li> <li> <p>Use Expected Calibration Error as metric but wish for high accuracy as well</p> </li> <li> <p>Tasks : NLI, Paraphrase Detection, Commonsense Reasoning</p> </li> <li> <p>In-domain : Transformer-based models generally more accurate, better calibrated</p> </li> <li> <p>Out-of-domain : Robust out of domain accuracy but still quite high calibration errors</p> </li> <li> <p>How to fix calibration errors?</p> </li> <li> <p>Temperature scaling good for in-domain while label smoothing good for out-of-domain <img src="/assets/images/2020-11-22-13-15-42.png" alt="" /> <a href="8c716ab6-e253-4b05-8167-ad399382adbb">interesting</a></p> </li> </ul> <h2 id="etc-encoding-long-and-structured-inputs-in-transformers"> <a href="#etc-encoding-long-and-structured-inputs-in-transformers" aria-labelledby="etc-encoding-long-and-structured-inputs-in-transformers" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> ETC: Encoding Long and Structured Inputs in Transformers </h2> <p>Joshua Ainslie, Santiago Ontanon, Chris Alberti, Vaclav Cvicek, Zachary Fisher, Philip Pham, Anirudh Ravula, Sumit Sanghai, Qifan Wang, Li Yang</p> <p><a href="https://slideslive.com/38938951">https://slideslive.com/38938951</a> <a href="https://www.aclweb.org/anthology/2020.emnlp-main.19">https://www.aclweb.org/anthology/2020.emnlp-main.19</a></p> <ul> <li> <p>Attention doesn‚Äôt scale</p> </li> <li>Global-local attention : <ul> <li>Global attends to all tokens</li> <li>Local attends locally</li> <li>Similar to Longformer</li> </ul> </li> <li> <p>Relative position representations : encode arbitrary structure relations between input tokens</p> </li> <li> <p>Contrastive Predictive Coding : Pre-training objective to use global summary tokens</p> </li> <li> <p>ETC : Have global tokens that can attend everywhere and local ones with sliding window : linear complexity in length <img src="/assets/images/2020-11-16-17-32-16.png" alt="" /></p> </li> <li> <p>Relative position representations : <img src="/assets/images/2020-11-16-17-33-38.png" alt="" /> Encourage global tokens to serve as sentence summaries</p> </li> <li> <p>CPC : In addition to MLM : also predict sentences using global tokens, try to predict sentence embeddings</p> </li> <li>SotA long answer performance on several datasets <img src="/assets/images/2020-11-22-13-15-42.png" alt="" /> <a href="8c716ab6-e253-4b05-8167-ad399382adbb">interesting</a></li> </ul> <h2 id="ternarybert"> <a href="#ternarybert" aria-labelledby="ternarybert" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> TernaryBERT </h2> <p><img src="/assets/images/2020-11-22-13-15-42.png" alt="" /> <a href="8c716ab6-e253-4b05-8167-ad399382adbb">interesting</a></p> <p>15x smaller size with comparable accuracy to BERT</p> <p>Tiny model with distillation + ternary quantization (-1, 0, 1) with good results</p> <p><a href="https://virtual.2020.emnlp.org/paper_main.2783.html">https://virtual.2020.emnlp.org/paper_main.2783.html</a></p> <h2 id="repulsive-attention-rethinking-multi-head-attention-as-bayesian-inference"> <a href="#repulsive-attention-rethinking-multi-head-attention-as-bayesian-inference" aria-labelledby="repulsive-attention-rethinking-multi-head-attention-as-bayesian-inference" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Repulsive Attention: Rethinking Multi-head Attention as Bayesian Inference </h2> <p>Bang An, Jie Lyu, Zhenyi Wang, Chunyuan Li, Changwei Hu, Fei Tan, Ruiyi Zhang, Yifan Hu, Changyou Chen</p> <p><a href="https://virtual.2020.emnlp.org/paper_main.903.html">https://virtual.2020.emnlp.org/paper_main.903.html</a></p> <p>Cast multi-head attention to bayesian framework Apply repulsive forces to heads such that they capture different effects.</p> <h2 id="self-supervised-meta-learning-for-few-shot-natural-language-classification-tasks"> <a href="#self-supervised-meta-learning-for-few-shot-natural-language-classification-tasks" aria-labelledby="self-supervised-meta-learning-for-few-shot-natural-language-classification-tasks" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Self-Supervised Meta-Learning for Few-Shot Natural Language Classification Tasks </h2> <p>Trapit Bansal, Rishikesh Jha, Tsendsuren Munkhdalai, Andrew McCallum</p> <p><a href="https://virtual.2020.emnlp.org/paper_main.2793.html">https://virtual.2020.emnlp.org/paper_main.2793.html</a></p> <p>Can we already optimize for future finetuning during pretraining? Metalearning, distribution over tasks</p> <p>Improvements for few shot learning, even for small LM</p> <p>Variation of MLM : Always hide the same k words =&gt; classification among the k classes <img src="/assets/images/2020-11-22-13-15-42.png" alt="" /> <a href="8c716ab6-e253-4b05-8167-ad399382adbb">interesting</a></p> <hr> <footer> <p class="text-small text-grey-dk-000 mb-0"></p> </footer> </div> </div> <div class="search-overlay"></div> </div> </body> </html>
